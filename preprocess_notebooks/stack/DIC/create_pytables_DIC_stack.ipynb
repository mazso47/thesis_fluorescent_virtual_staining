{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3b853a-10d7-4fb8-9ee7-1d138375d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8970cb-1f10-43b0-8daf-1e557f9682b5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf55a90-609b-4068-884e-94b9f835dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainPyTable(object):\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        \n",
    "    def create_pytable(self):\n",
    "        # Define PyTable file and groups\n",
    "        with tables.open_file(self.fname, mode='w') as hdf5_file:\n",
    "            root = hdf5_file.root\n",
    "\n",
    "            img_group = hdf5_file.create_group(root, 'img', 'Image data')\n",
    "            mask_group = hdf5_file.create_group(root, 'mask', 'Mask data')\n",
    "\n",
    "            compression_filters = tables.Filters(complevel=9, complib='zlib', shuffle=False)\n",
    "\n",
    "            # Create datasets for images and masks\n",
    "            img_array = hdf5_file.create_earray(img_group, 'data', tables.UInt16Atom(), shape=(0,) + (6, 1024, 1024), filters=compression_filters)\n",
    "            mask_array = hdf5_file.create_earray(mask_group, 'data', tables.UInt16Atom(), shape=(0,) + (4, 1024, 1024), filters=compression_filters)\n",
    "\n",
    "        print(f\"PyTable file created: {self.fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8352c57-90fa-4bff-8508-86f7d3d2c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTable file created: /media/local-admin/lightmycells/thesis/code/pytables/stack/DIC_6_cubic/study_DIC_train_stack.pytable\n"
     ]
    }
   ],
   "source": [
    "train_fname = '/media/local-admin/lightmycells/thesis/code/pytables/stack/DIC_6_cubic/study_DIC_train_stack.pytable'\n",
    "# Create PyTable instance\n",
    "train_pytable = TrainPyTable(train_fname)\n",
    "train_pytable.create_pytable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be7a5b9-555e-4bb8-9c76-94591b737c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTable file created: /media/local-admin/lightmycells/thesis/code/pytables/stack/DIC_6_cubic/study_DIC_valid_stack.pytable\n"
     ]
    }
   ],
   "source": [
    "valid_fname = '/media/local-admin/lightmycells/thesis/code/pytables/stack/DIC_6_cubic/study_DIC_valid_stack.pytable'\n",
    "# Create PyTable instance\n",
    "valid_pytable = TrainPyTable(valid_fname)\n",
    "valid_pytable.create_pytable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ed9eb-d453-4e59-87aa-6c5e09e571fc",
   "metadata": {},
   "source": [
    "## Test & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb22845-f459-46ca-b229-37a67a294d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestValidPyTable(object):\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        \n",
    "    def create_pytable(self):\n",
    "        # Define PyTable file and groups\n",
    "        with tables.open_file(self.fname, mode='w') as hdf5_file:\n",
    "            root = hdf5_file.root\n",
    "\n",
    "            img_group = hdf5_file.create_group(root, 'img', 'Image data')\n",
    "            mask_group = hdf5_file.create_group(root, 'mask', 'Mask data')\n",
    "\n",
    "            compression_filters = tables.Filters(complevel=5, complib='zlib', shuffle=False)\n",
    "            \n",
    "            # Create datasets for images and masks\n",
    "            img_array_2044 = hdf5_file.create_earray(img_group, 'data_2044', tables.UInt16Atom(), shape=(0,) + (6, 2044, 2048), filters=compression_filters)\n",
    "            mask_array_2044 = hdf5_file.create_earray(mask_group, 'data_2044', tables.UInt16Atom(), shape=(0,) + (4, 2044, 2048), filters=compression_filters)\n",
    "\n",
    "            img_array_980 = hdf5_file.create_earray(img_group, 'data_980', tables.UInt16Atom(), shape=(0,) + (6, 980, 1016), filters=compression_filters)\n",
    "            mask_array_980 = hdf5_file.create_earray(mask_group, 'data_980', tables.UInt16Atom(), shape=(0,) + (4, 980, 1016), filters=compression_filters)\n",
    "\n",
    "            img_array_2048 = hdf5_file.create_earray(img_group, 'data_2048', tables.UInt16Atom(), shape=(0,) + (6, 2048, 2048), filters=compression_filters)\n",
    "            mask_array_2048 = hdf5_file.create_earray(mask_group, 'data_2048', tables.UInt16Atom(), shape=(0,) + (4, 2048, 2048), filters=compression_filters)\n",
    "\n",
    "            img_array_512 = hdf5_file.create_earray(img_group, 'data_512', tables.UInt16Atom(), shape=(0,) + (6, 512, 512), filters=compression_filters)\n",
    "            mask_array_512 = hdf5_file.create_earray(mask_group, 'data_512', tables.UInt16Atom(), shape=(0,) + (4, 512, 512), filters=compression_filters)\n",
    "            \n",
    "            img_array_1300 = hdf5_file.create_earray(img_group, 'data_1300', tables.UInt16Atom(), shape=(0,) + (6, 1300, 1624), filters=compression_filters)\n",
    "            mask_array_1300 = hdf5_file.create_earray(mask_group, 'data_1300', tables.UInt16Atom(), shape=(0,) + (4, 1300, 1624), filters=compression_filters)\n",
    "\n",
    "            img_array_1200 = hdf5_file.create_earray(img_group, 'data_1200', tables.UInt16Atom(), shape=(0,) + (6, 1200, 1200), filters=compression_filters)\n",
    "            mask_array_1200 = hdf5_file.create_earray(mask_group, 'data_1200', tables.UInt16Atom(), shape=(0,) + (4, 1200, 1200), filters=compression_filters)\n",
    "                \n",
    "            img_array_966 = hdf5_file.create_earray(img_group, 'data_966', tables.UInt16Atom(), shape=(0,) + (6, 966, 1296), filters=compression_filters)\n",
    "            mask_array_966 = hdf5_file.create_earray(mask_group, 'data_966', tables.UInt16Atom(), shape=(0,) + (4, 966, 1296), filters=compression_filters)\n",
    "\n",
    "            img_array_1024 = hdf5_file.create_earray(img_group, 'data_1024', tables.UInt16Atom(), shape=(0,) + (6, 1024, 1024), filters=compression_filters)\n",
    "            mask_array_1024 = hdf5_file.create_earray(mask_group, 'data_1024', tables.UInt16Atom(), shape=(0,) + (4, 1024, 1024), filters=compression_filters)\n",
    "                \n",
    "\n",
    "           \n",
    "        print(f\"PyTable file created: {self.fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0267d68d-12ac-4b8f-b51d-e8ac5b89d519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTable file created: /media/local-admin/lightmycells/thesis/code/pytables/stack/DIC_6_cubic/study_DIC_test_stack.pytable\n"
     ]
    }
   ],
   "source": [
    "test_fname = '/media/local-admin/lightmycells/thesis/code/pytables/stack/DIC_6_cubic/study_DIC_test_stack.pytable'\n",
    "# Create PyTable instance\n",
    "test_pytable = TestValidPyTable(test_fname)\n",
    "test_pytable.create_pytable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda5d99-9716-4b0c-8df6-932c14b73c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
